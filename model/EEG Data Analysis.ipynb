{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import heapq\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "## Make sure to install autoreject from master as there is a bug in the latest release: http://autoreject.github.io/\n",
    "from autoreject import AutoReject, get_rejection_threshold, set_matplotlib_defaults\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Project and Unicorn specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = pathlib.Path().absolute().parent\n",
    "\n",
    "sample_data_folder = project_root / \"visual_stress_data\"\n",
    "sample_data_raw_files = list(sample_data_folder.glob(\"**/*.fif\"))\n",
    "print(\"Found {} *_raw.fif file(s)\".format(len(sample_data_raw_files)))\n",
    "\n",
    "petri_sample_data_raw_files = list(sample_data_folder.glob(\"**/petri*.fif\"))\n",
    "print(\"Found {} petri*_raw.fif file(s)\".format(len(petri_sample_data_raw_files)))\n",
    "\n",
    "gel_sample_data_raw_files = list(sample_data_folder.glob(\"**/gel*.fif\"))\n",
    "print(\"Found {} gel*_raw.fif file(s)\".format(len(gel_sample_data_raw_files)))\n",
    "\n",
    "channel_name_mapping = {\n",
    "    \"EEG0\": \"Fz\",\n",
    "    \"EEG1\": \"C3\",\n",
    "    \"EEG2\": \"Cz\",\n",
    "    \"EEG3\": \"C4\",\n",
    "    \"EEG4\": \"Pz\",\n",
    "    \"EEG5\": \"PO7\",\n",
    "    \"EEG6\": \"Oz\",\n",
    "    \"EEG7\": \"PO8\",\n",
    "}\n",
    "\n",
    "event_dict = {\"focused\": 1, \"blurred\": 2, \"end\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load montage file and display montage\n",
    "#### API Docs\n",
    "- [read_custom_montage](https://mne.tools/stable/generated/mne.channels.read_custom_montage.html#mne-channels-read-custom-montage)\n",
    "- [plot](https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_locs_file = (\n",
    "    project_root / \"Resources\" / \"locs_electrode_placement_gtec_unicorn_standard.locs\"\n",
    ")\n",
    "\n",
    "montage = mne.channels.read_custom_montage(channel_locs_file)\n",
    "_ = montage.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_raw_from_fif(file):\n",
    "\n",
    "    raw = mne.io.read_raw_fif(file, preload=True)\n",
    "    \n",
    "    # fix event object format (flip and get increment event ids by one as mne doesn't like an event id of 0)\n",
    "    raw.info[\"events\"] = np.array(\n",
    "        [[e[\"list\"][2], e[\"list\"][1], e[\"list\"][0] + 1] for e in raw.info[\"events\"]]\n",
    "    )\n",
    "\n",
    "    # rename channels and set channel positions\n",
    "    mne.rename_channels(raw.info, channel_name_mapping)\n",
    "    raw.set_montage(montage)\n",
    "    \n",
    "    # Pick the EEG channels and exclude the Fz channel\n",
    "    raw = raw.pick(\"eeg\", exclude=['Fz'])\n",
    "\n",
    "    # Bandpass filter. Later when splitting Epochs make sure to take into account the Nyquist frequency\n",
    "    raw.filter(2, 40, n_jobs=-1)\n",
    "\n",
    "    # Throw away everything until the first event\n",
    "    raw.crop(tmin=raw.info[\"events\"][0][0] / raw.info[\"sfreq\"])\n",
    "\n",
    "    # Set average reference\n",
    "    raw.set_eeg_reference(\"average\", projection=False)\n",
    "    \n",
    "    # Scale values to microvolts\n",
    "    raw = raw.apply_function(lambda a: a * 1e-7)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_log_level = mne.set_log_level(\"WARNING\")\n",
    "\n",
    "raws = [get_raw_from_fif(f) for f in gel_sample_data_raw_files]\n",
    "\n",
    "mne.set_log_level(old_log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some debugging outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: concatenate_raws will modify raws[0]!\n",
    "raw, events = mne.concatenate_raws(raws, events_list=[r.info[\"events\"] for r in raws])\n",
    "\n",
    "# Update events object\n",
    "raw.info[\"events\"] = events\n",
    "\n",
    "\n",
    "display(Markdown(\"**n_times of modified raw:** {}\".format(raw.n_times)))\n",
    "\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augument data\n",
    "To make it simpler to split the data into short epochs later, insert artifical events after every blur and focused event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the virtual events for every second.\n",
    "augumented_events_lists = [\n",
    "    [[e_1[0] + (250*3) * i, 0, e_1[2]] for i in range(math.floor((e_2[0] - e_1[0]) / 250/3))]\n",
    "    for e_1, e_2 in zip(raw.info[\"events\"][:-1], raw.info[\"events\"][1:])\n",
    "]\n",
    "\n",
    "# insert the events into the raw object\n",
    "raw.info[\"events\"] = np.array(list(heapq.merge(*augumented_events_lists)))\n",
    "\n",
    "# Drop the temporary events with id 3\n",
    "raw.info[\"events\"] = np.array(list(filter(lambda e: e[2] != 3, raw.info[\"events\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Plot\n",
    "**Let's have a look at our data.** Set duration to some high number (>10000) to see all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = raw.plot(\n",
    "    events=raw.info[\"events\"],\n",
    "    event_color={1: \"green\", 2: \"blue\", 3: \"black\"},\n",
    "    duration=160,\n",
    "    scalings=\"2e-6\",\n",
    "    clipping=\"clamp\",  # or \"transparent\" \"clamp\"\n",
    "    show_scalebars=False,\n",
    "    show_scrollbars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Epochs\n",
    "Each event is three second long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    raw.info[\"events\"],\n",
    "    event_id={\"focused\": 1, \"blurred\": 2},\n",
    "    tmin=0,\n",
    "    tmax=3,\n",
    "    baseline=(None, None),\n",
    "    preload=True,\n",
    "    reject_by_annotation=True,\n",
    "    reject=None,\n",
    "    flat=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_criteria = get_rejection_threshold(epochs)\n",
    "print('Reject criteria: {}'.format((reject_criteria)))\n",
    "\n",
    "display(Markdown(\"**Epochs dropped due to bad channels:**\"))\n",
    "\n",
    "old_log_level = mne.set_log_level(\"WARNING\") # lower log level as drop_bad generates a lot of output if many epochs are dropped\n",
    "epochs.drop_bad(reject=reject_criteria)\n",
    "mne.set_log_level(old_log_level)\n",
    "\n",
    "_ = epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalize Events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds_we_care_about = [\"focused\", \"blurred\"]\n",
    "\n",
    "display(Markdown(\"**Epochs dropped to prevent bias:**\"))\n",
    "epochs.equalize_event_counts(conds_we_care_about)  # this operates in-place\n",
    "\n",
    "focused_epochs = epochs[\"focused\"]\n",
    "blurred_epochs = epochs[\"blurred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are left with {} epochs for training.'.format((len(epochs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = epochs.plot(\n",
    "    events=events,\n",
    "    scalings=\"auto\",\n",
    "    show_scrollbars=False,\n",
    "    n_epochs=40,\n",
    "    event_colors={1: \"red\", 2: \"blue\"},\n",
    "    epoch_colors=[[\"red\" if e[2] == 1 else \"blue\"] * len(raw.get_data()) for e in epochs.events],\n",
    ")\n",
    "\n",
    "_ = focused_epochs.plot(\n",
    "    events=events,\n",
    "    scalings=\"auto\",\n",
    "    show_scrollbars=False,\n",
    "    epoch_colors=[[\"red\" if e[2] == 1 else \"blue\"] * len(raw.get_data()) for e in focused_epochs.events],\n",
    ")\n",
    "_ = blurred_epochs.plot(\n",
    "    events=events,\n",
    "    scalings=\"auto\",\n",
    "    show_scrollbars=False,\n",
    "    epoch_colors=[[\"red\" if e[2] == 1 else \"blue\"] * len(raw.get_data()) for e in blurred_epochs.events],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = focused_epochs.plot_image()\n",
    "_ = blurred_epochs.plot_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make out any trends in power spectrum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = focused_epochs.plot_psd(\n",
    "    average=False\n",
    ")\n",
    "_ = blurred_epochs.plot_psd(\n",
    "    average=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = focused_epochs.plot_psd_topomap(ch_type=\"eeg\", normalize=True)\n",
    "_ = blurred_epochs.plot_psd_topomap(ch_type=\"eeg\", normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.arange(7, 30, 3)\n",
    "power = mne.time_frequency.tfr_morlet(\n",
    "    focused_epochs, n_cycles=2, return_itc=False, freqs=frequencies, decim=2\n",
    ")\n",
    "_ = power.plot()\n",
    "\n",
    "power = mne.time_frequency.tfr_morlet(\n",
    "    blurred_epochs, n_cycles=2, return_itc=False, freqs=frequencies, decim=2\n",
    ")\n",
    "_ = power.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Model Processing and Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data to PSD\n",
    "freq_data = mne.decoding.PSDEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = epochs.get_data()\n",
    "numpy_data = numpy_data.reshape(numpy_data.shape[0], -1)\n",
    "print(\"Shape of original data is {}\".format(numpy_data.shape))\n",
    "\n",
    "labels = epochs.events[:,2]-1\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(numpy_data, labels, test_size=0.33, random_state=42)\n",
    "print(\"Shape of X_train is {}\".format(X_train.shape))\n",
    "print(\"Shape of labels is {}\".format(y_train.shape))\n",
    "\n",
    "# Applying SVC to the data for a baseline machine learning model\n",
    "clf = make_pipeline(freq_data, StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.metrics import hamming_loss, roc_curve, classification_report\n",
    "\n",
    "print(\"F1 score is {}\".format(f1_score(y_test, predictions)))\n",
    "print(\"Accuracy score is {}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"Hamming Loss of the classifier is {}\\n\".format(hamming_loss(y_test, predictions)))\n",
    "\n",
    "print(\"\\n CLASSIFICATION REPORT \\n\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# plot_confusion_matrix(clf, X_test, y_test)\n",
    "plot_roc_curve(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('model_svm_gel_3sec_fixed.pkl', 'wb') as myfile:\n",
    "    pickle.dump(clf, myfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
